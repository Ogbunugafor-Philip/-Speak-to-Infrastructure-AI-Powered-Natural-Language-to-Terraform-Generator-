# dual_feedback.py - Enhanced Version
# Advanced visual feedback for both voice and text interactions

import time
import sys
from datetime import datetime

# Try to import speech recognition
try:
    import speech_recognition as sr
    SPEECH_AVAILABLE = True
except ImportError:
    SPEECH_AVAILABLE = False


class InteractionSession:
    """Track interaction session data."""
    
    def __init__(self):
        self.voice_inputs = []
        self.text_inputs = []
        self.start_time = datetime.now()
        self.current_mode = "text"
    
    def add_voice_input(self, text, confidence, status="success"):
        """Add voice input to history."""
        self.voice_inputs.append({
            "text": text,
            "confidence": confidence,
            "status": status,
            "timestamp": datetime.now()
        })
    
    def add_text_input(self, text, status="received"):
        """Add text input to history."""
        self.text_inputs.append({
            "text": text,
            "status": status,
            "timestamp": datetime.now(),
            "char_count": len(text)
        })
    
    def get_stats(self):
        """Get session statistics."""
        return {
            "voice_count": len(self.voice_inputs),
            "text_count": len(self.text_inputs),
            "total_inputs": len(self.voice_inputs) + len(self.text_inputs),
            "duration": (datetime.now() - self.start_time).seconds,
            "avg_voice_confidence": sum(v["confidence"] for v in self.voice_inputs) / len(self.voice_inputs) if self.voice_inputs else 0
        }


def display_voice_feedback(spoken_text, confidence=0.0, is_listening=False, status="Processing"):
    """Show enhanced visual feedback for voice interactions."""
    print("\n" + "â•"*60)
    print("ğŸ¤ " + "VOICE INTERFACE".center(56) + " ğŸ¤")
    print("â•"*60)
    
    # Status indicator
    status_icons = {
        "listening": "ğŸ”´ LISTENING",
        "processing": "ğŸ”„ PROCESSING",
        "success": "âœ… SUCCESS",
        "low_confidence": "âš ï¸  LOW CONFIDENCE",
        "error": "âŒ ERROR"
    }
    
    if is_listening:
        print(f"\n{status_icons.get('listening', 'ğŸ”Š ACTIVE')}")
        print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚  ğŸ“¢ Speak clearly into your microphone                  â”‚")
        print("â”‚  â¹ï¸  The system will detect when you're finished        â”‚")
        print("â”‚  ğŸ’¡ Tip: Speak at a normal pace                         â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    else:
        status_key = "success" if confidence >= 0.8 else "low_confidence" if confidence > 0 else "processing"
        print(f"\n{status_icons.get(status_key, 'âœ… COMPLETE')}")
        
        if spoken_text:
            print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            print(f"â”‚ ğŸ’¬ TRANSCRIPTION:                                       â”‚")
            print(f"â”‚    \"{spoken_text[:50]}{'...' if len(spoken_text) > 50 else ''}\"")
            print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    # Confidence visualization
    if confidence > 0:
        print(f"\nğŸ“Š CONFIDENCE ANALYSIS:")
        
        # Progress bar
        bar_length = 40
        filled = int(confidence * bar_length)
        bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
        
        # Color-coded indicator
        if confidence >= 0.9:
            indicator = "ğŸŸ¢ EXCELLENT"
        elif confidence >= 0.8:
            indicator = "ğŸŸ¡ GOOD"
        elif confidence >= 0.6:
            indicator = "ğŸŸ  FAIR"
        else:
            indicator = "ğŸ”´ POOR"
        
        print(f"   [{bar}] {confidence:.1%}")
        print(f"   {indicator}")
        
        # Recommendations
        if confidence < 0.8:
            print("\nğŸ’¡ IMPROVEMENT TIPS:")
            if confidence < 0.5:
                print("   â€¢ Speak more clearly and slowly")
                print("   â€¢ Move to a quieter environment")
                print("   â€¢ Check microphone positioning")
            elif confidence < 0.7:
                print("   â€¢ Reduce background noise")
                print("   â€¢ Speak slightly louder")
            else:
                print("   â€¢ Minor clarity improvement needed")
    
    print("â•"*60)


def display_text_feedback(typed_text, is_typing=False, status="received"):
    """Show enhanced visual feedback for text interactions."""
    print("\n" + "â•"*60)
    print("âŒ¨ï¸  " + "TEXT INTERFACE".center(56) + " âŒ¨ï¸")
    print("â•"*60)
    
    if is_typing:
        print("\nâœï¸  WAITING FOR INPUT")
        print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚  âŒ¨ï¸  Type your response below                            â”‚")
        print("â”‚  â†µ  Press Enter when finished                           â”‚")
        print("â”‚  ğŸ’¡ Tip: Be clear and specific                          â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    else:
        print("\nâœ… INPUT RECEIVED")
        
        if typed_text:
            print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            print(f"â”‚ ğŸ“ YOUR INPUT:                                          â”‚")
            print(f"â”‚    \"{typed_text[:50]}{'...' if len(typed_text) > 50 else ''}\"")
            print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            
            # Text statistics
            print(f"\nğŸ“Š TEXT ANALYSIS:")
            print(f"   â€¢ Characters: {len(typed_text)}")
            print(f"   â€¢ Words: {len(typed_text.split())}")
            
            # Quality indicators
            if len(typed_text) < 3:
                print("   âš ï¸  Very short input - consider adding details")
            elif len(typed_text) < 10:
                print("   ğŸŸ¡ Short input - acceptable")
            else:
                print("   ğŸŸ¢ Good level of detail")
    
    print("â•"*60)


def show_unified_dashboard(voice_data, text_data, current_mode, show_comparison=True):
    """Display enhanced unified dashboard with both panels."""
    print("\n" + "â•”"*60)
    print("â•‘" + " ğŸ¯ UNIFIED INTERACTION DASHBOARD ".center(118) + "â•‘")
    print("â•š"*60)
    
    # Mode indicator
    mode_display = {
        "voice": "ğŸ¤ VOICE MODE",
        "text": "âŒ¨ï¸  TEXT MODE",
        "hybrid": "ğŸ”„ HYBRID MODE",
        "auto": "ğŸ¤– AUTO MODE"
    }
    
    print(f"\nâš¡ CURRENT MODE: {mode_display.get(current_mode, current_mode.upper())}")
    print("â”€"*60)
    
    # Side-by-side panels
    print("\n" + "â”Œ" + "â”€"*28 + "â”¬" + "â”€"*29 + "â”")
    print("â”‚" + " ğŸ¤ VOICE PANEL ".center(28) + "â”‚" + " âŒ¨ï¸  TEXT PANEL ".center(29) + "â”‚")
    print("â”œ" + "â”€"*28 + "â”¼" + "â”€"*29 + "â”¤")
    
    # Voice panel content
    if voice_data:
        v_status = voice_data.get('status', 'N/A')[:12]
        v_text = voice_data.get('text', 'None')[:20]
        v_conf = voice_data.get('confidence', 0)
        
        print(f"â”‚ Status: {v_status:<15} â”‚", end="")
    else:
        print("â”‚ â¸ï¸  No voice activity    â”‚", end="")
    
    # Text panel content
    if text_data:
        t_status = text_data.get('status', 'N/A')[:12]
        t_text = text_data.get('text', 'None')[:20]
        
        print(f" Status: {t_status:<16} â”‚")
        print(f"â”‚ Text: {v_text:<17} â”‚ Input: {t_text:<18} â”‚")
        
        if voice_data:
            conf_bar = "â–ˆ" * int(v_conf * 10) + "â–‘" * (10 - int(v_conf * 10))
            print(f"â”‚ Conf: [{conf_bar}] {v_conf:.0%} â”‚", end="")
        else:
            print(f"â”‚                          â”‚", end="")
        
        t_chars = text_data.get('char_count', len(t_text))
        print(f" Chars: {t_chars:<17} â”‚")
    else:
        print(" â¸ï¸  No text activity      â”‚")
        if voice_data:
            v_text = voice_data.get('text', 'None')[:20]
            v_conf = voice_data.get('confidence', 0)
            conf_bar = "â–ˆ" * int(v_conf * 10) + "â–‘" * (10 - int(v_conf * 10))
            print(f"â”‚ Text: {v_text:<17} â”‚                           â”‚")
            print(f"â”‚ Conf: [{conf_bar}] {v_conf:.0%} â”‚                           â”‚")
        else:
            print("â”‚                          â”‚                           â”‚")
    
    print("â””" + "â”€"*28 + "â”´" + "â”€"*29 + "â”˜")
    
    # Comparison section
    if show_comparison and voice_data and text_data:
        print("\nğŸ“Š INPUT COMPARISON:")
        print(f"   Voice: {len(voice_data.get('text', ''))} chars, {voice_data.get('confidence', 0):.0%} confidence")
        print(f"   Text:  {len(text_data.get('text', ''))} chars, 100% accuracy")
        
        # Suggest optimal mode
        if voice_data.get('confidence', 0) < 0.7:
            print("\nğŸ’¡ SUGGESTION: Consider using text mode for better accuracy")
        else:
            print("\nâœ… Both modes performing well!")


def animate_listening():
    """Animated listening indicator."""
    print("\nğŸ¤ Listening", end="", flush=True)
    for _ in range(3):
        for indicator in ["   ", ".  ", ".. ", "..."]:
            print(f"\rğŸ¤ Listening{indicator}", end="", flush=True)
            time.sleep(0.3)
    print("\rğŸ¤ Listening... âœ…")


def show_session_summary(session):
    """Display comprehensive session summary."""
    stats = session.get_stats()
    
    print("\n" + "â•”"*60)
    print("â•‘" + " ğŸ“Š SESSION SUMMARY ".center(118) + "â•‘")
    print("â•š"*60)
    
    print(f"\nâ±ï¸  DURATION: {stats['duration']} seconds")
    print(f"ğŸ“ TOTAL INPUTS: {stats['total_inputs']}")
    
    print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ INPUT BREAKDOWN:                                        â”‚")
    print(f"â”‚   ğŸ¤ Voice inputs: {stats['voice_count']:<35} â”‚")
    print(f"â”‚   âŒ¨ï¸  Text inputs:  {stats['text_count']:<35} â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    if stats['voice_count'] > 0:
        print(f"\nğŸ“Š VOICE PERFORMANCE:")
        print(f"   Average confidence: {stats['avg_voice_confidence']:.1%}")
        
        if stats['avg_voice_confidence'] >= 0.85:
            print("   ğŸŸ¢ Excellent voice recognition quality!")
        elif stats['avg_voice_confidence'] >= 0.70:
            print("   ğŸŸ¡ Good voice recognition quality")
        else:
            print("   ğŸ”´ Voice recognition could be improved")
    
    # Show recent inputs
    print("\nğŸ“œ RECENT ACTIVITY:")
    
    if session.voice_inputs:
        print("\n  ğŸ¤ Last voice input:")
        last_voice = session.voice_inputs[-1]
        print(f"     \"{last_voice['text'][:50]}\"")
        print(f"     Confidence: {last_voice['confidence']:.1%}")
    
    if session.text_inputs:
        print("\n  âŒ¨ï¸  Last text input:")
        last_text = session.text_inputs[-1]
        print(f"     \"{last_text['text'][:50]}\"")
        print(f"     Characters: {last_text['char_count']}")
    
    print("\n" + "â•"*60)


def interactive_feedback_demo():
    """Interactive demonstration of the dual feedback system."""
    print("\n" + "â•”"*60)
    print("â•‘" + " ğŸ¨ DUAL FEEDBACK VISUALIZATION SYSTEM ".center(118) + "â•‘")
    print("â•š"*60)
    
    print("\nThis system provides real-time visual feedback for both")
    print("voice and text inputs, helping you track interaction quality.")
    
    if SPEECH_AVAILABLE:
        print("\nâœ… Real speech recognition is AVAILABLE")
    else:
        print("\nâš ï¸  Speech recognition not available (simulation mode)")
    
    print("\n" + "â”€"*60)
    
    session = InteractionSession()
    
    while True:
        print("\n" + "ğŸ”·"*30)
        print("   INTERACTION MENU")
        print("ğŸ”·"*30)
        print("\n  [1] Simulate voice input")
        print("  [2] Simulate text input")
        print("  [3] Show unified dashboard")
        print("  [4] View session summary")
        print("  [5] Full demo sequence")
        print("  [q] Quit")
        print("â”€"*60)
        
        choice = input("\nSelect option: ").strip().lower()
        
        if choice == 'q':
            break
        
        elif choice == '1':
            # Simulate voice input
            print("\nğŸ“ VOICE INPUT SIMULATION")
            session.current_mode = "voice"
            
            user_input = input("What would you say? (or press Enter for demo): ").strip()
            if not user_input:
                user_input = "Create a database server with MySQL"
            
            # Show listening state
            display_voice_feedback("", confidence=0, is_listening=True)
            animate_listening()
            
            # Simulate processing
            confidence = float(input("\nSimulate confidence (0.0-1.0, or Enter for random): ").strip() or f"{0.75 + (hash(user_input) % 25) / 100}")
            
            # Show result
            display_voice_feedback(user_input, confidence=confidence, is_listening=False)
            
            session.add_voice_input(user_input, confidence)
        
        elif choice == '2':
            # Simulate text input
            print("\nğŸ“ TEXT INPUT SIMULATION")
            session.current_mode = "text"
            
            display_text_feedback("", is_typing=True)
            
            user_input = input("\nYour input: ").strip()
            if not user_input:
                user_input = "Ubuntu 22.04 with 16GB RAM"
            
            display_text_feedback(user_input, is_typing=False)
            
            session.add_text_input(user_input)
        
        elif choice == '3':
            # Show unified dashboard
            voice_data = session.voice_inputs[-1] if session.voice_inputs else None
            text_data = session.text_inputs[-1] if session.text_inputs else None
            
            show_unified_dashboard(voice_data, text_data, session.current_mode)
        
        elif choice == '4':
            # Show session summary
            show_session_summary(session)
        
        elif choice == '5':
            # Full demo sequence
            print("\nğŸ¬ RUNNING FULL DEMO SEQUENCE...")
            time.sleep(1)
            
            # Demo 1: High confidence voice
            print("\nğŸ“ 1. High Confidence Voice Input")
            time.sleep(1)
            display_voice_feedback("Create an AWS EC2 instance", confidence=0.95, is_listening=False)
            session.add_voice_input("Create an AWS EC2 instance", 0.95)
            time.sleep(2)
            
            # Demo 2: Text input
            print("\nğŸ“ 2. Text Input")
            time.sleep(1)
            display_text_feedback("t3.medium with 50GB storage", is_typing=False)
            session.add_text_input("t3.medium with 50GB storage")
            time.sleep(2)
            
            # Demo 3: Unified dashboard
            print("\nğŸ“ 3. Unified Dashboard")
            time.sleep(1)
            show_unified_dashboard(session.voice_inputs[-1], session.text_inputs[-1], "hybrid")
            time.sleep(2)
            
            # Demo 4: Low confidence voice
            print("\nğŸ“ 4. Low Confidence Voice Input")
            time.sleep(1)
            display_voice_feedback("databse servr", confidence=0.42, is_listening=False)
            session.add_voice_input("databse servr", 0.42, "low_confidence")
            time.sleep(2)
            
            # Demo 5: Final summary
            print("\nğŸ“ 5. Session Summary")
            time.sleep(1)
            show_session_summary(session)
            
            print("\nğŸ‰ Demo sequence complete!")
        
        else:
            print("âŒ Invalid option")
    
    # Final summary
    print("\n" + "â•”"*60)
    print("â•‘" + " ğŸ‘‹ SESSION ENDED ".center(118) + "â•‘")
    print("â•š"*60)
    
    show_session_summary(session)
    
    print("\nâœ¨ Thank you for exploring the dual feedback system!")


if __name__ == "__main__":
    try:
        interactive_feedback_demo()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Demo interrupted by user")
    except Exception as e:
        print(f"\nâŒ Error: {e}")